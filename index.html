<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>Rethinking Visual-language Model in Face Forensic: Multi-modal Interpretable Forged Face Detector</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static//favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <style>
    /* 样式部分 */
    .popup {
      display: none;
      position: fixed;
      top: 50%;
      left: 50%;
      transform: translate(-50%, -50%);
      background-color: white;
      box-shadow: 0px 4px 16px rgba(0, 0, 0, 0.2);
      z-index: 9999;
      max-width: 80%; 
      max-height: 80vh;
    }

    .popup video {
      width: 100%;
      height: auto;
    }

    .close-btn {
      position: absolute;
      top: 10px;
      right: 20px;
      font-size: 20px;
      cursor: pointer;
      color: red;
    }

    .overlay {
      display: none;
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background-color: rgba(0, 0, 0, 0.7);
      z-index: 9998;
    }

    img {
      width: 180px;
      height: 180px;
    }

    .image-grid {
      display: grid;
      grid-template-columns: repeat(5, 1fr);
      grid-gap: 15px;
      margin-top: 20px;
    }
    
    .image-grid img {
      width: 180px;
      height: 180px;
    }

    .image-gallery {
            display: flex;
            justify-content: center;
            gap: 20px;
            flex-wrap: wrap;
        }
    .image-half-warehouse {
        display: inline-block;
        width: 45%;
        justify-content: center;
        margin: 30px;
        box-sizing: border-box;
    }
    .image-container {
        position: relative;
        text-align: center;
        max-width: 180px; /* Set a max width for each image container */
    }
    
    .link-text {
      color: darkcyan;
      text-decoration: underline;
    }

    .link-placeholder {
      font-size: 14px;
    }

    .normal_text {
      font-size: 20px;
    }
  </style>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-fullwidth">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Rethinking Visual-language Model in Face Forensic:<br> Multi-modal Interpretable Forged Face Detector</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Anonymous Submission
            </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href="https://arxiv.org/pdf/2404.06692.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
             <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<div class="container is-fullwidth">
  <div class="columns is-centered">
    <div class="column has-text-centered">
      <h2 class="title is-2">Demo Videos</h2>
        <h2 class="title is-2">Click links below each image to view results</h2>
        <h3 class="title is-3">FF++</h3>
        <div class="image-gallery">
          <div class="image-container">
            <img src="static\demo\images\FF++\0_052_108.jpg" alt="Video 1">
            <p class="triggerText" data-video="static\demo\videos\ours\FF++\0_052_108.mp4">Ours</p>
            <p class="triggerText" data-video="static\demo\videos\LLaVA\FF++\0_052_108.mov">LLaVA-1.5(CVPR24)</p>
            <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\FF++\0_052_108.mov">DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\demo\images\FF++\0_106_198.jpg" alt="Video 2">
            <p class="triggerText" data-video="static\demo\videos\ours\FF++\0_106_198.mp4">Ours</p>
            <p class="triggerText" data-video="static\demo\videos\LLaVA\FF++\0_106_198.mov">LLaVA-1.5(CVPR24)</p>
            <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\FF++\0_106_198.mov">DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\demo\images\FF++\NeuralTextures_871_814.jpg" alt="Video 5">
            <p class="triggerText" data-video="static\demo\videos\ours\FF++\NeuralTextures_871_814.mp4">Ours</p>
            <p class="triggerText" data-video="static\demo\videos\LLaVA\FF++\NeuralTextures_871_814.mov">LLaVA-1.5(CVPR24)</p>
            <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\FF++\NeuralTextures_871_814.mov">DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\demo\images\FF++\Face2Face_027_009.jpg" alt="Video 3">
            <p class="triggerText" data-video="static\demo\videos\ours\FF++\Face2Face_027_009.mp4">Ours</p>
            <p class="triggerText" data-video="static\demo\videos\LLaVA\FF++\Face2Face_027_009.mov">LLaVA-1.5(CVPR24)</p>
            <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\FF++\Face2Face_027_009.mov">DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\demo\images\FF++\Face2Face_193_030.jpg" alt="Video 4">
            <p class="triggerText" data-video="static\demo\videos\ours\FF++\Face2Face_193_030.mp4">Ours</p>
            <p class="triggerText" data-video="static\demo\videos\LLaVA\FF++\Face2Face_193_030.mov">LLaVA-1.5(CVPR24)</p>
            <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\FF++\Face2Face_193_030.mov">DDVQA-BLIP(ECCV24)</p>
          </div>
        </div>

        <div class="image-half-warehouse">
          <h3 class="title is-3">FFIW</h3>
          <div class="image-gallery">
            <div class="image-container">
              <img src="static\demo\images\FFIW\Picture1.png" alt="Video 8">
              <p class="triggerText" data-video="static\demo\videos\ours\FFIW\Picture1.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\FFIW\Picture1.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\FFIW\Picture1.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\FFIW\230.png" alt="Video 7">
              <p class="triggerText" data-video="static\demo\videos\ours\FFIW\230.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\FFIW\230.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\FFIW\230.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\FFIW\test_00000004.png" alt="Video 6">
              <p class="triggerText" data-video="static\demo\videos\ours\FFIW\test_00000004.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\FFIW\test_00000004.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\FFIW\test_00000004.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
          </div>
        </div>

        <div class="image-half-warehouse">
          <h3 class="title is-3">Wild-Deepfake</h3>
          <div class="image-gallery">
            <div class="image-container">
              <img src="static\demo\images\DFW\68_10_678.png" alt="Video 8">
              <p class="triggerText" data-video="static\demo\videos\ours\DFW\68_10_678.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\DFW\68_10_678.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\DFW\68_10_678.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\DFW\7_220_1000.png" alt="Video 6">
              <p class="triggerText" data-video="static\demo\videos\ours\DFW\7_220_1000.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\DFW\7_220_1000.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\DFW\7_220_1000.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\DFW\18_66_1167.png" alt="Video 7">
              <p class="triggerText" data-video="static\demo\videos\ours\DFW\18_66_1167.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\DFW\18_66_1167.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\DFW\18_66_1167.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
          </div>
        </div>

        <div class="image-half-warehouse">
          <h3 class="title is-3">Celeb-DF</h3>
          <div class="image-gallery">
            <div class="image-container">
              <img src="static\demo\images\Celeb_DF\id58_id54_0002_0000.png" alt="Video 8">
              <p class="triggerText" data-video="static\demo\videos\ours\Celeb_DF\id58_id54_0002_0000.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\Celeb_DF\id58_id54_0002_0000.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\Celeb_DF\id58_id54_0002_0000.mp4">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\Celeb_DF\id0_id4_0004_0000.png" alt="Video 6">
              <p class="triggerText" data-video="static\demo\videos\ours\Celeb_DF\id0_id4_0004_0000.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\Celeb_DF\id0_id4_0004_0000.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\Celeb_DF\id0_id4_0004_0000.mp4">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\Celeb_DF\id59_id61_0001_0000.png" alt="Video 7">
              <p class="triggerText" data-video="static\demo\videos\ours\Celeb_DF\id59_id61_0001_0000.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\Celeb_DF\id59_id61_0001_0000.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\Celeb_DF\id59_id61_0001_0000.mp4">DDVQA-BLIP(ECCV24)</p>
            </div>
          </div>
        </div>

        <div class="image-half-warehouse">
          <h3 class="title is-3">DFDC</h3>
          <div class="image-gallery">
            <div class="image-container">
              <img src="static\demo\images\DFDC\Picture1.png" alt="Video 6">
              <p class="triggerText" data-video="static\demo\videos\ours\DFDC\Picture1.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\DFDC\Picture1.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\DFDC\Picture1.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\DFDC\Picture2.png" alt="Video 7">
              <p class="triggerText" data-video="static\demo\videos\ours\DFDC\Picture2.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\DFDC\Picture2.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\DFDC\Picture2.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\DFDC\Picture3.png" alt="Video 8">
              <p class="triggerText" data-video="static\demo\videos\ours\DFDC\Picture3.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\DFDC\Picture3.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\DFDC\Picture3.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
          </div>
        </div>

        <div class="image-half-warehouse">
          <h3 class="title is-3">StyleGANv2</h3>
          <div class="image-gallery">
            <div class="image-container">
              <img src="static\demo\images\StyleGANv2\10055_7.jpg" alt="Video 6">
              <p class="triggerText" data-video="static\demo\videos\ours\StyleGANv2\10055_7.mov">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\StyleGANv2\10055_7.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\StyleGANv2\10055_7.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\StyleGANv2\1.png" alt="Video 7">
              <p class="triggerText" data-video="static\demo\videos\ours\StyleGANv2\1.mov">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\StyleGANv2\1.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\StyleGANv2\1.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\StyleGANv2\2.png" alt="Video 8">
              <p class="triggerText" data-video="static\demo\videos\ours\StyleGANv2\2.mov">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\StyleGANv2\2.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\StyleGANv2\2.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
          </div>
        </div>

        <div class="image-half-warehouse">
          <h3 class="title is-3">Instant-ID</h3>
          <div class="image-gallery">
            <div class="image-container">
              <img src="static\demo\images\instantid\Oprah_Winfrey.png" alt="Video 6">
              <p class="triggerText" data-video="static\demo\videos\ours\instantid\Oprah_Winfrey.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\instantid\Oprah_Winfrey.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\instantid\Oprah_Winfrey.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\instantid\Jeff_Bezos.png" alt="Video 7">
              <p class="triggerText" data-video="static\demo\videos\ours\instantid\Jeff_Bezos.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\instantid\Jeff_Bezos.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\instantid\Jeff_Bezos.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\instantid\Scarlett_Johansson.png" alt="Video 8">
              <p class="triggerText" data-video="static\demo\videos\ours\instantid\Scarlett_Johansson.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\LLaVA\instantid\Scarlett_Johansson.mov">LLaVA-1.5(CVPR24)</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\instantid\Scarlett_Johansson.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
          </div>
        </div>

        <div class="image-half-warehouse">
          <h3 class="title is-3">Midjourney</h3>
          <div class="image-gallery">
            <div class="image-container">
              <img src="static\demo\images\midjourney\person109.png" alt="Video 6">
              <p class="triggerText" data-video="static\demo\videos\ours\midjourney\person109.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\midjourney\person109.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\midjourney\person15.png" alt="Video 7">
              <p class="triggerText" data-video="static\demo\videos\ours\midjourney\person15.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\midjourney\person15.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\midjourney\person196.png" alt="Video 8">
              <p class="triggerText" data-video="static\demo\videos\ours\midjourney\person196.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\midjourney\person196.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
          </div>
        </div>

        <div class="image-half-warehouse">
          <h3 class="title is-3">Real</h3>
          <div class="image-gallery">
            <div class="image-container">
              <img src="static\demo\images\real\Picture3.png" alt="Video 6">
              <p class="triggerText" data-video="static\demo\videos\ours\real\Picture3.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\real\Picture3.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\real\Picture2.jpg" alt="Video 7">
              <p class="triggerText" data-video="static\demo\videos\ours\real\Picture2.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\real\Picture2.mov">DDVQA-BLIP(ECCV24)</p>
            </div>
            <div class="image-container">
              <img src="static\demo\images\real\Picture1.jpg" alt="Video 8">
              <p class="triggerText" data-video="static\demo\videos\ours\real\Picture1.mp4">Ours</p>
              <p class="triggerText" data-video="static\demo\videos\DDVQA_BLIP\real\Picture1.mov"">DDVQA-BLIP(ECCV24)</p>
            </div>
          </div>
        </div>

        <!-- <h4 class="title is-4">FF++</h2>

        <div class="image-gallery">
          <div class="image-container">
            <img src="static\images\FF++\Deepfakes_000_003.jpg" alt="Video 11">
            <p class="triggerText" data-video="static\videos\FF++\Deepfakes_000_003.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>

          <div class="image-container">
            <img src="static\images\FF++\Deepfakes_138_142.jpg" alt="Video 12">
            <p class="triggerText" data-video="static\videos\FF++\Deepfakes_138_142.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\Deepfakes_048_029.jpg" alt="Video 13">
            <p class="triggerText" data-video="static\videos\FF++\Deepfakes_048_029.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\Deepfakes_380_358.jpg" alt="Video 14">
            <p class="triggerText" data-video="static\videos\FF++\Deepfakes_380_358.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\Deepfakes_842_714.jpg" alt="Video 15">
            <p class="triggerText" data-video="static\videos\FF++\Deepfakes_842_714.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\Deepfakes_517_521.jpg" alt="Video 16">
            <p class="triggerText" data-video="static\videos\FF++\Deepfakes_517_521.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\Face2Face_389_480.jpg" alt="Video 17">
            <p class="triggerText" data-video="static\videos\FF++\Face2Face_389_480.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\Deepfakes_741_731.jpg" alt="Video 18">
            <p class="triggerText" data-video="static\videos\FF++\Deepfakes_741_731.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\FaceSwap_161_141.jpg" alt="Video 19">
            <p class="triggerText" data-video="static\videos\FF++\FaceSwap_161_141.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\FaceSwap_012_026.jpg" alt="Video 20">
            <p class="triggerText" data-video="static\videos\FF++\FaceSwap_012_026.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\NeuralTextures_073_024.jpg" alt="Video 21">
            <p class="triggerText" data-video="static\videos\FF++\NeuralTextures_073_024.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\Face2Face_418_507.jpg" alt="Video 22">
            <p class="triggerText" data-video="static\videos\FF++\Face2Face_418_507.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\Face2Face_625_650.jpg" alt="Video 23">
            <p class="triggerText" data-video="static\videos\FF++\Face2Face_625_650.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\Face2Face_494_445.jpg" alt="Video 24">
            <p class="triggerText" data-video="static\videos\FF++\Face2Face_494_445.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\Face2Face_384_932.jpg" alt="Video 25">
            <p class="triggerText" data-video="static\videos\FF++\Face2Face_384_932.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          </div>
          <h4 class="title is-4">Diffusion</h2>

          <div class="image-gallery">
          <div class="image-container">
            <img src="static\images\Dalle2\person107.png" alt="Video 26">
            <p class="triggerText" data-video="static\videos\diffusion\dalle2_person107.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\Dalle2\person124.png" alt="Video 27">
            <p class="triggerText" data-video="static\videos\diffusion\dalle2_person124.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\instantid\Alan_Turing_a_man_skiing_on_the_snowy_mountain_14.png" alt="Video 28">
            <p class="triggerText" data-video="static\videos\diffusion\instantid_alan_turing.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\instantid\Jeff_Bezos_a_man_wearing_sunglasses_and_necklace,_close-up,_in_the_view_of_right_side_1.png" alt="Video 29">
            <p class="triggerText" data-video="static\videos\diffusion\instantid_jeff_bezos.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\instantid\Mark_Zuckerberg_a_man_crying_disappointedly,_with_tears_flowing_15.png" alt="Video 30">
            <p class="triggerText" data-video="static\videos\diffusion\instantid_mark_zuckerberg.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          </div>
          <h4 class="title is-4">Real</h2>

          <div class="image-gallery">
          <div class="image-container">
            <img src="static\images\FF++\original_000.jpg" alt="Video 31">
            <p class="triggerText" data-video="static\videos\FF++\original_000.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\original_044.jpg" alt="Video 32">
            <p class="triggerText" data-video="static\videos\FF++\original_044.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          
          <div class="image-container">
            <img src="static\images\FF++\original_319.jpg" alt="Video 33">
            <p class="triggerText" data-video="static\videos\FF++\original_319.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\original_701.jpg" alt="Video 34">
            <p class="triggerText" data-video="static\videos\FF++\original_701.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          <div class="image-container">
            <img src="static\images\FF++\original_801.jpg" alt="Video 35">
            <p class="triggerText" data-video="static\videos\FF++\original_801.mp4">Ours</p>
            <p class='link-placeholder'>LLaVA-1.5(CVPR24)</p>
            <p class='link-placeholder'>DDVQA-BLIP(ECCV24)</p>
          </div>
          </div> -->
              <!-- Overlay background -->
      <div id="overlay" class="overlay"></div>

      <!-- Popup window -->
      <div id="popup" class="popup">
        <span id="closeBtn" class="close-btn">&times;</span>
        <video id="popupVideo" controls>
          <source src="" type="video/mp4">
          Your browser does not support the video tag.
        </video>
      </div>
    </div>
  </div>
</div>


<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
          <div class="content">
            <video id="similar_work-video" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/3.mp4"
                      type="video/mp4">
            </video>
          </div>
      </div>
    </div>
  </div>
</div>
</section> -->

<section class="section">
  <div class="container is-fullwidth">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p class="normal_text">
            Deepfake detection is a long-established research topic crucial for combating the spread of malicious misinformation. 
            Unlike previous methods that provide either binary classification results or textual explanations for deepfake detection, we propose a novel method that delivers both simultaneously. 
            Our method harnesses the multi-modal learning power of the pre-trained CLIP and the unprecedented interpretability of large language models (LLMs) to enhance both the generalization and interpretability of deepfake detection. 
            Specifically, we introduce a multi-modal face forgery detector (M2F2-Det) that employs specially designed face forgery prompt learning, integrating zero-shot learning capabilities of the pre-trained CLIP to improve generalization to unseen forgeries.
            Also, M2F2-Det incorporates the LLM to provide detailed explanations for detection decisions, offering strong interpretability by bridging the gap between natural language and the subtle nuances of facial forgery detection. 
            Empirically, we evaluate M2F2-Det for both detection and sentence generation tasks, on both of which M2F2-Det achieves state-of-the-art performance, showing its effectiveness in detecting and explaining diverse and unseen forgeries. 
            Code and models will be released upon publication.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section class="section">
  <div class="container is-fullwidth">  
    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Introduction</h2>
        <div class="content image">
          <img src="static/figs/teaser_1-1.png", alt="thumbnail">
        </div>
        <div class="content has-text-justified">
          <p class="normal_text">
            (a) and (b) represent conventional deepfake detectors and DDVQA-BLIP, which take an image as the input and output the fake probability and description, respectively. (c) In this work, we propose a multi-modal face forgery detector (M2F2-Det) that produces both fake probability and reasoning descriptions.
          </p>
         </div>

      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-fullwidth">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Method</h2>
        <!-- <div class="content image">

          <img src="static/figs/teaser_2-1.png", alt="thumbnail">
        </div>
          <div class="content has-text-justified">
              <p>
                (a) Forgery Prompt Learning (FPL) optimizes <i>UF-prompts</i> and <i>layer-wise forgery tokens</i> (LF tokens) for CLIP's adaptation to deepfake detection. 
                UF-prompts consist of three segments (<i>e.g.</i>, trainable general forgery tokens (<i>i.e.</i>, <b>V<sub>1</sub></b>, <b>V<sub>2</sub></b>, and <b>V<sub>3</sub></b>) and specific forgery tokens (<i>i.e.</i>, <b>V<sub>4</sub></b>, <b>V<sub>5</sub></b>, and <b>V<sub>6</sub></b>), as well as fixed tokens "Forged Face").              </p>
          </div> -->
        <div class="content image">
          <img src="static/figs/main_arch_v3.png", alt="main figure">
        </div>
        <div class="content has-text-justified">
          <p class="normal_text">
            (a) The Multi-modal Face Forgery Detector (M2F2-Det) contains
    pre-trained CLIP image and text encoders (<i>i.e.</i>, \( \mathcal{E}_{I} \) and \( \mathcal{E}_{T} \)), the deepfake encoder, as well as the LLM. 
    Taking universal forgery prompts (UF-prompts) as inputs, \( \mathcal{E}_{T} \) generates global text embedding, <i>e.g.</i>, <b>g<sup>T</sup></b>, that helps obtain the forged attention mask, <i>e.g.</i>, <b>M<sub>b</sub></b>. 
    The deepfake encoder utilizes the bridge adapter, <i>i.e.</i>, \( \mathcal{E}_{A} \), for detecting face forgeries, and the LLM generates descriptions based on outputs from \( \mathcal{E}_{I} \) and learned forgery representation (<b>F<sup>0</sup></b>).
    (b) In the pre-trained CLIP text encoder, we introduce trainable layer-wise forgery tokens as inputs to each Transformer encoder layer.
         </p>
      </div>
        <!-- <div class="content image">
          <img src="static/figs/bridge_adapter.png", alt="main figure">
        </div> -->
        <!-- <div class="content has-text-justified">
          <p>
            Deepfake detection is a long-established research topic crucial for combating the spread of malicious misinformation. 
            Unlike previous methods that provide either binary classification results or textual explanations for deepfake detection, we propose a novel method that delivers both simultaneously. 
            Our method harnesses the multi-modal learning power of the pre-trained CLIP and the unprecedented interpretability of large language models (LLMs) to enhance both the generalization and interpretability of deepfake detection. 
            Specifically, we introduce a multi-modal face forgery detector (M2F2-Det) that employs specially designed face forgery prompt learning, integrating zero-shot learning capabilities of the pre-trained CLIP to improve generalization to unseen forgeries.
            Also, M2F2-Det incorporates the LLM to provide detailed explanations for detection decisions, offering strong interpretability by bridging the gap between natural language and the subtle nuances of facial forgery detection. 
            Empirically, we evaluate M2F2-Det on both detection and sentence generation tasks, on both of which M2F2-Det achieves competitive performance, showing its effectiveness in detecting and explaining diverse and unseen forgeries. 
            Code and models will be released upon publication.
          </p> -->
      <!-- <div class="content has-text-justified">
        <p>
          The illustration on the Bridge Adapter, in which &#x0398; represents the transformation conducted by Eq.6 in the paper. [Key: T-Block: transformer encoder block; Block: convolution block.]
      </p>
      </div> -->
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>


<section class="section">
  <div class="container is-fullwidth">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Experiment</h2>
        <!-- <div class="content image">

          <img max-width="-48%" src="static/figs/radar_v2.png", alt="thumbnail">
          <img max-width="-48%" src="static/figs/main_arch_v3.png", alt="main figure">
        </div> -->
        <!-- <div class="content image">
          <img src="static/figs/gen_result-1.png", alt="main figure">
        </div> -->
        <!-- <div class="content has-text-justified">
          <p style="text-align: center;">
            Qualitative results of generated textual explanations from DDVQA-BLIP, GPT-4o, and M2F2-Det.
        </p>
        </div> -->
        <div class="content image">
          <img src="static/figs/heatmap_v6.png", alt="main figure">
        </div>
        <div class="content has-text-justified">
          <p class="normal_text" style="text-align: center;">
            Forged attention maps on samples from 6 datasets.
        </p>
        </div>
        <div class="content image">
          <img src="static/figs/heatmap_v7-1.png", alt="main figure">
        </div>
        <div class="content has-text-justified">
          <p class="normal_text" style="text-align: center;">
            Additional generated forged attention map. [Key: LF: Layer-wise forgery tokens.]
        </p>
        </div>
        <!-- <div class="content has-text-justified">
          <p>
            Deepfake detection is a long-established research topic crucial for combating the spread of malicious misinformation. 
            Unlike previous methods that provide either binary classification results or textual explanations for deepfake detection, we propose a novel method that delivers both simultaneously. 
            Our method harnesses the multi-modal learning power of the pre-trained CLIP and the unprecedented interpretability of large language models (LLMs) to enhance both the generalization and interpretability of deepfake detection. 
            Specifically, we introduce a multi-modal face forgery detector (M2F2-Det) that employs specially designed face forgery prompt learning, integrating zero-shot learning capabilities of the pre-trained CLIP to improve generalization to unseen forgeries.
            Also, M2F2-Det incorporates the LLM to provide detailed explanations for detection decisions, offering strong interpretability by bridging the gap between natural language and the subtle nuances of facial forgery detection. 
            Empirically, we evaluate M2F2-Det on both detection and sentence generation tasks, on both of which M2F2-Det achieves competitive performance, showing its effectiveness in detecting and explaining diverse and unseen forgeries. 
            Code and models will be released upon publication.
          </p> -->
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>



<!-- Paper poster -->
<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <div class="content">
          <h2 class="title">Manuscript (Accepeted by CVPR 2024)</h2>

          <iframe  src="./static/pdf/2404.06692.pdf" width="100%" height="550">
              </iframe>
        </div>
      </div>
    </div>
  </div>
</section> -->

<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  title     ={Perception-Oriented Video Frame Interpolation via Asymmetric Blending},
  author    ={Wu, Guangyang and Tao, Xin and Li, Changlin and Wang, Wenyi and Liu, Xiaohong and Zheng, Qingqing},
  journal   ={arXiv preprint arXiv:2404.06692},
  year      ={2024},
}</code></pre>
  </div>
</section> -->

<script>
  // 等待 DOM 完全加载后再运行脚本
  document.addEventListener('DOMContentLoaded', function () {
    // 获取元素
    const triggerImages = document.querySelectorAll(".triggerImage");
    const triggerTexts = document.querySelectorAll(".triggerText");

    const popup = document.getElementById("popup");
    const popupVideo = document.getElementById("popupVideo");
    const closeBtn = document.getElementById("closeBtn");
    const overlay = document.getElementById("overlay");

    // 为每张图片添加点击事件
    triggerImages.forEach(function (img) {
      img.onclick = function () {
        const videoSrc = img.getAttribute("data-video");
        popupVideo.src = videoSrc;
        popup.style.display = "block";
        overlay.style.display = "block";
        popupVideo.playbackRate = 1.5; // Adjust video speed (1.5x speed)
        popupVideo.style.width = "100%"
      };
    });
 
    triggerTexts.forEach(function (t) {
      t.style.color = 'darkcyan'
      t.style.textDecoration = 'underline'
      t.style.cursor='pointer'
      t.onclick = function () {
        const videoSrc = t.getAttribute("data-video");
        popupVideo.src = videoSrc;
        popup.style.display = "block";
        overlay.style.display = "block";
        popupVideo.playbackRate = 1.5; // Adjust video speed (1.5x speed)
        popupVideo.style.width = "100%"
      };
    });
    
    // 关闭弹窗
    closeBtn.onclick = function () {
      popup.style.display = "none";
      overlay.style.display = "none";
      popupVideo.pause(); // 关闭时暂停视频
    }

    // 点击遮罩层关闭弹窗
    overlay.onclick = function () {
      popup.style.display = "none";
      overlay.style.display = "none";
      popupVideo.pause(); // 关闭时暂停视频
    }

  });
</script>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            We borrow the website <a href="https://github.com/nerfies/nerfies.github.io">template</a> from this,
            many thanks for their great help!
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
